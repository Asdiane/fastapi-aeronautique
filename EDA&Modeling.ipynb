{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4529f4-c258-478e-a4d1-b9fd63718a91",
   "metadata": {},
   "source": [
    "<h2>Création ou extration des données pour obtenir le fichier csv</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcae1dec-bd62-4707-8dce-c523486a6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation de pandas et requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06583bd5-fe32-45e6-a52e-cded267f88d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ahmed\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "541da064-e26c-4690-a938-a41121965fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données enregistrées (500 vols) dans vols_grand_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = \"85a23812c5c3bde3c8c179a8da7ad744\"\n",
    "BASE_URL = \"http://api.aviationstack.com/v1/flights\"\n",
    "\n",
    "# Paramètres de la requête\n",
    "params = {\n",
    "    \"access_key\" : API_KEY,\n",
    "    \"limit\": 100,\n",
    "    \"flight_status\": \"landed\"\n",
    "}\n",
    "\n",
    "# Liste pour stocker les vols\n",
    "all_flights = []\n",
    "\n",
    "# Récupérer plusieurs pages de données\n",
    "for offset in range(0, 500, 100):  # 500 vols, par pas de 100\n",
    "    params[\"offset\"] = offset  # Changer l’offset à chaque itération\n",
    "\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json().get(\"data\", [])\n",
    "        \n",
    "        for flight in data:\n",
    "            all_flights.append([\n",
    "                flight.get(\"flight_date\"),\n",
    "                flight.get(\"flight_status\"),\n",
    "                flight[\"departure\"].get(\"airport\") if flight.get(\"departure\") else None,\n",
    "                flight[\"departure\"].get(\"iata\") if flight.get(\"departure\") else None,\n",
    "                flight[\"departure\"].get(\"delay\") if flight.get(\"departure\") else None,\n",
    "                flight[\"arrival\"].get(\"airport\") if flight.get(\"arrival\") else None,\n",
    "                flight[\"arrival\"].get(\"iata\") if flight.get(\"arrival\") else None,\n",
    "                flight[\"arrival\"].get(\"delay\") if flight.get(\"arrival\") else None,\n",
    "                flight[\"airline\"].get(\"name\") if flight.get(\"airline\") else None,\n",
    "                flight[\"flight\"].get(\"number\") if flight.get(\"flight\") else None,\n",
    "                flight[\"flight\"].get(\"iata\") if flight.get(\"flight\") else None\n",
    "            ])\n",
    "    \n",
    "    else:\n",
    "        print(f\"⚠️ Erreur avec l'API (Offset {offset}): {response.status_code}\")\n",
    "        break  # Stopper en cas d'erreur pour éviter de gaspiller des requêtes\n",
    "\n",
    "# Création du DataFrame Pandas\n",
    "df = pd.DataFrame(all_flights, columns=[\n",
    "    \"Date\", \"Statut\", \"Aeroport_Depart\", \"Code_IATA_Depart\", \"Retard_Depart\",\n",
    "    \"Aeroport_Arrivee\", \"Code_IATA_Arrivee\", \"Retard_Arrivee\",\n",
    "    \"Compagnie\", \"Numero_Vol\", \"Code_IATA_Vol\"\n",
    "])\n",
    "\n",
    "# Sauvegarde en CSV\n",
    "df.to_csv(\"vols_grand_dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"Données enregistrées ({len(df)} vols) dans vols_grand_dataset.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a62d6-2342-4230-9db8-d3130405f34a",
   "metadata": {},
   "source": [
    " <h2>Charger et vérifier les données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0458617-9ecc-4936-92f3-6f9dba9684e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Statut   Aeroport_Depart Code_IATA_Depart  Retard_Depart  \\\n",
      "0  2025-03-15  landed            Broome              BME            NaN   \n",
      "1  2025-03-15  landed            Hobart              HBA           10.0   \n",
      "2  2025-03-15  landed  Singapore Changi              SIN           25.0   \n",
      "3  2025-03-15  landed  Singapore Changi              SIN           14.0   \n",
      "4  2025-03-15  landed          Dushanbe              DYU            NaN   \n",
      "\n",
      "                  Aeroport_Arrivee Code_IATA_Arrivee  Retard_Arrivee  \\\n",
      "0                        Kununurra               KNX             NaN   \n",
      "1  Melbourne - Tullamarine Airport               MEL             NaN   \n",
      "2     Newark Liberty International               EWR             NaN   \n",
      "3                            Civil               TRZ             NaN   \n",
      "4                           Urumqi               URC             NaN   \n",
      "\n",
      "            Compagnie  Numero_Vol Code_IATA_Vol  \n",
      "0        Thai AirAsia       608.0         FD608  \n",
      "1              Qantas      1236.0        QF1236  \n",
      "2  Singapore Airlines        22.0          SQ22  \n",
      "3   Air India Express       681.0         IX681  \n",
      "4           Somon Air       303.0         SZ303  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Date               500 non-null    object \n",
      " 1   Statut             500 non-null    object \n",
      " 2   Aeroport_Depart    499 non-null    object \n",
      " 3   Code_IATA_Depart   500 non-null    object \n",
      " 4   Retard_Depart      402 non-null    float64\n",
      " 5   Aeroport_Arrivee   497 non-null    object \n",
      " 6   Code_IATA_Arrivee  500 non-null    object \n",
      " 7   Retard_Arrivee     88 non-null     float64\n",
      " 8   Compagnie          497 non-null    object \n",
      " 9   Numero_Vol         494 non-null    float64\n",
      " 10  Code_IATA_Vol      494 non-null    object \n",
      "dtypes: float64(3), object(8)\n",
      "memory usage: 43.1+ KB\n",
      "None\n",
      "       Retard_Depart  Retard_Arrivee   Numero_Vol\n",
      "count     402.000000    8.800000e+01   494.000000\n",
      "mean       12.149254    3.299354e+05  4254.137652\n",
      "std        11.756151    3.094967e+06  3097.785172\n",
      "min         1.000000    1.000000e+00     6.000000\n",
      "25%         5.000000    2.000000e+00   782.000000\n",
      "50%         9.000000    7.000000e+00  4507.000000\n",
      "75%        15.000000    1.400000e+01  6845.250000\n",
      "max       112.000000    2.903337e+07  9840.000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Charger le dataset\n",
    "df = pd.read_csv(\"vols_grand_dataset.csv\")\n",
    "\n",
    "# Afficher les premières lignes\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# Vérifier les colonnes et valeurs manquantes\n",
    "print(df.info())\n",
    "\n",
    "# Vérifier les statistiques des retards\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78bd2a-b4f1-4221-b1c7-41b9c2c5cb81",
   "metadata": {},
   "source": [
    "<h2>Nettoyage et Préparation des Dnnées</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8448847-1762-4900-b3cf-c6e3ebe682e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 402 entries, 1 to 499\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Date               402 non-null    object \n",
      " 1   Statut             402 non-null    int32  \n",
      " 2   Aeroport_Depart    402 non-null    object \n",
      " 3   Code_IATA_Depart   402 non-null    object \n",
      " 4   Retard_Depart      402 non-null    int32  \n",
      " 5   Aeroport_Arrivee   399 non-null    object \n",
      " 6   Code_IATA_Arrivee  402 non-null    object \n",
      " 7   Retard_Arrivee     402 non-null    int32  \n",
      " 8   Compagnie          399 non-null    object \n",
      " 9   Numero_Vol         398 non-null    float64\n",
      " 10  Code_IATA_Vol      398 non-null    object \n",
      "dtypes: float64(1), int32(3), object(7)\n",
      "memory usage: 33.0+ KB\n",
      "None\n",
      "         Date  Statut   Aeroport_Depart Code_IATA_Depart  Retard_Depart  \\\n",
      "1  2025-03-15       2            Hobart              HBA             10   \n",
      "2  2025-03-15       2  Singapore Changi              SIN             25   \n",
      "3  2025-03-15       2  Singapore Changi              SIN             14   \n",
      "6  2025-03-15       2          Shenzhen              SZX             10   \n",
      "7  2025-03-15       2          Shenzhen              SZX             10   \n",
      "\n",
      "                  Aeroport_Arrivee Code_IATA_Arrivee  Retard_Arrivee  \\\n",
      "1  Melbourne - Tullamarine Airport               MEL               0   \n",
      "2     Newark Liberty International               EWR               0   \n",
      "3                            Civil               TRZ               0   \n",
      "6       Suvarnabhumi International               BKK               0   \n",
      "7       Suvarnabhumi International               BKK               0   \n",
      "\n",
      "                    Compagnie  Numero_Vol Code_IATA_Vol  \n",
      "1                      Qantas      1236.0        QF1236  \n",
      "2          Singapore Airlines        22.0          SQ22  \n",
      "3           Air India Express       681.0         IX681  \n",
      "6  Thai Airways International      6455.0        TG6455  \n",
      "7               Air China LTD      7979.0        CA7979  \n"
     ]
    }
   ],
   "source": [
    "# Supprimer les vols sans Retard_Depart\n",
    "df_clean = df.dropna(subset=[\"Retard_Depart\"]).copy()\n",
    "\n",
    "# Remplacer les NaN dans Retard_Arrivee par 0 (sans inplace=True)\n",
    "df_clean[\"Retard_Arrivee\"] = df_clean[\"Retard_Arrivee\"].fillna(0)\n",
    "\n",
    "# Convertir les retards en entiers\n",
    "df_clean[\"Retard_Depart\"] = df_clean[\"Retard_Depart\"].astype(int)\n",
    "df_clean[\"Retard_Arrivee\"] = df_clean[\"Retard_Arrivee\"].astype(int)\n",
    "\n",
    "# Convertir les statuts en valeurs numériques\n",
    "df_clean[\"Statut\"] = df_clean[\"Statut\"].map({\n",
    "    \"scheduled\": 0,\n",
    "    \"active\": 1,\n",
    "    \"landed\": 2,\n",
    "    \"cancelled\": -1\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "# Vérification des données après nettoyage\n",
    "print(df_clean.info())\n",
    "print(df_clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f1cae-a4f4-405f-b858-a5de9532f2e5",
   "metadata": {},
   "source": [
    "# Entraînement du Modèle Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de5c3be2-4863-41f4-bd80-ffe4438aa50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 vols suspects détectés sur 402.\n",
      "           Date  Statut                 Aeroport_Depart Code_IATA_Depart  \\\n",
      "98   2025-03-15       2  Guangzhou Baiyun International              CAN   \n",
      "134  2025-03-15       2         Hong Kong International              HKG   \n",
      "166  2025-03-15       2                         Wenzhou              WNZ   \n",
      "183  2025-03-15       2         Hong Kong International              HKG   \n",
      "264  2025-03-15       2      Christchurch International              CHC   \n",
      "\n",
      "     Retard_Depart                                   Aeroport_Arrivee  \\\n",
      "98              38                                          Don Muang   \n",
      "134             41                                    Seoul (Incheon)   \n",
      "166            112                                           Shenzhen   \n",
      "183             40  Taiwan Taoyuan International (Chiang Kai Shek ...   \n",
      "264             48                             Auckland International   \n",
      "\n",
      "    Code_IATA_Arrivee  Retard_Arrivee    Compagnie  Numero_Vol Code_IATA_Vol  \\\n",
      "98                DMK               4      AirAsia       533.0         AK533   \n",
      "134               ICN               2   Korean Air       178.0         KE178   \n",
      "166               SZX              19  SF Airlines      7277.0        O37277   \n",
      "183               TPE              11      EVA Air      6530.0        BR6530   \n",
      "264               AKL              34      Jetstar       226.0         JQ226   \n",
      "\n",
      "     Anomalie  Anomalie_DBSCAN  \n",
      "98         -1                0  \n",
      "134        -1                0  \n",
      "166        -1               -1  \n",
      "183        -1                0  \n",
      "264        -1                0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Sélection des variables pour l'entraînement\n",
    "df_ml = df_clean[[\"Statut\", \"Retard_Depart\", \"Retard_Arrivee\"]]\n",
    "\n",
    "# Création et entraînement du modèle Isolation Forest\n",
    "model = IsolationForest(contamination=0.05, random_state=42)\n",
    "df_clean[\"Anomalie\"] = model.fit_predict(df_ml)\n",
    "\n",
    "# Compter les anomalies détectées\n",
    "anomalies = df_clean[df_clean[\"Anomalie\"] == -1]\n",
    "print(f\"{len(anomalies)} vols suspects détectés sur {len(df_clean)}.\")\n",
    "print(anomalies.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b66cfd0e-49f5-4c6b-b765-ae50bf63313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 vols suspects détectés avec DBSCAN sur 402.\n",
      "           Date  Statut Aeroport_Depart Code_IATA_Depart  Retard_Depart  \\\n",
      "166  2025-03-15       2         Wenzhou              WNZ            112   \n",
      "\n",
      "    Aeroport_Arrivee Code_IATA_Arrivee  Retard_Arrivee    Compagnie  \\\n",
      "166         Shenzhen               SZX              19  SF Airlines   \n",
      "\n",
      "     Numero_Vol Code_IATA_Vol  Anomalie  Anomalie_DBSCAN  \n",
      "166      7277.0        O37277        -1               -1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_ml)\n",
    "\n",
    "# Entraîner DBSCAN\n",
    "dbscan = DBSCAN(eps=2, min_samples=3).fit(df_scaled)\n",
    "df_clean[\"Anomalie_DBSCAN\"] = dbscan.labels_\n",
    "\n",
    "# Vérifier les anomalies détectées\n",
    "dbscan_anomalies = df_clean[df_clean[\"Anomalie_DBSCAN\"] == -1]\n",
    "print(f\"{len(dbscan_anomalies)} vols suspects détectés avec DBSCAN sur {len(df_clean)}.\")\n",
    "print(dbscan_anomalies.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2da2d6-af53-4b8d-8e71-fa8369569aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc4b09-f6d8-4f02-9252-b9d4a2885f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8262ad7-a9f9-46cd-9d6d-521e28dd4d77",
   "metadata": {},
   "source": [
    "<h2>Script qui englobe Isolation Forest and DBSCAN </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf57c062-cbae-4573-9ff0-e563cc9e6628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Détection terminée ! 1 anomalies trouvées.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Charger les données de vols\n",
    "df = pd.read_csv(\"vols_grand_dataset.csv\")\n",
    "\n",
    "# Nettoyage et prétraitement\n",
    "df_clean = df.dropna(subset=[\"Retard_Depart\"]).copy()\n",
    "df_clean[\"Retard_Arrivee\"] = df_clean[\"Retard_Arrivee\"].fillna(0)\n",
    "\n",
    "df_clean[\"Retard_Depart\"] = df_clean[\"Retard_Depart\"].astype(int)\n",
    "df_clean[\"Retard_Arrivee\"] = df_clean[\"Retard_Arrivee\"].astype(int)\n",
    "\n",
    "df_clean[\"Statut\"] = df_clean[\"Statut\"].map({\n",
    "    \"scheduled\": 0, \"active\": 1, \"landed\": 2, \"cancelled\": -1\n",
    "}).fillna(0).astype(int)\n",
    "\n",
    "# Préparation des variables pour les modèles\n",
    "df_ml = df_clean[[\"Statut\", \"Retard_Depart\", \"Retard_Arrivee\"]]\n",
    "\n",
    "# Isolation Forest\n",
    "model_iso = IsolationForest(contamination=0.05, random_state=42)\n",
    "df_clean[\"Anomalie_ISO\"] = model_iso.fit_predict(df_ml)\n",
    "\n",
    "# DBSCAN (Normalisation nécessaire)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_ml)\n",
    "\n",
    "model_dbscan = DBSCAN(eps=2, min_samples=3)\n",
    "df_clean[\"Anomalie_DBSCAN\"] = model_dbscan.fit_predict(df_scaled)\n",
    "\n",
    "# Marquer les anomalies finales (vols détectés par les deux modèles)\n",
    "df_clean[\"Anomalie_Final\"] = np.where(\n",
    "    (df_clean[\"Anomalie_ISO\"] == -1) & (df_clean[\"Anomalie_DBSCAN\"] == -1), -1, 1\n",
    ")\n",
    "\n",
    "# Exporter les résultats dans un CSV\n",
    "df_clean.to_csv(\"vols_anomalies.csv\", index=False, encoding=\"utf-8\")\n",
    "print(f\"Détection terminée ! {len(df_clean[df_clean['Anomalie_Final'] == -1])} anomalies trouvées.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b074fb-6f04-4fb1-9e88-23266bb4e980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57214c1f-b6bc-4302-9efb-4aeec2c922f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096cee8e-a8d9-4406-9605-bc23c714fc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
